{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 美国USGS径流数据\n",
    "\n",
    "这部分主要参考了博客[径流观测数据](http://mengfeimu.com/2019/03/06/streamflow/)\n",
    "\n",
    "USGS [National Water Information System (NWIS)](https://waterdata.usgs.gov/nwis)，公开数据。\n",
    "\n",
    "径流站点信息查询：\n",
    "\n",
    "[NWIS](https://waterdata.usgs.gov/nwis)中的Site Information和[Map of all sites with links to all available water data for individual sites](https://maps.waterdata.usgs.gov/mapper/index.html).\n",
    "\n",
    "批量下载："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://waterdata.usgs.gov/nwis/dv?cb_00060=on&format=rdb&site_no=02096846&referred_module=sw&period=&begin_date=2011-01-01&end_date=2012-12-31\n",
      "<class 'list'>\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29]\n",
      "  agency_cd   site_no    datetime  86273_00060_00001 86273_00060_00001_cd  \\\n",
      "0      USGS  02096846  2011-01-01               1.00                    A   \n",
      "1      USGS  02096846  2011-01-02               1.68                    A   \n",
      "2      USGS  02096846  2011-01-03               3.63                    A   \n",
      "3      USGS  02096846  2011-01-04               3.16                    A   \n",
      "4      USGS  02096846  2011-01-05               2.27                    A   \n",
      "\n",
      "   86274_00060_00002 86274_00060_00002_cd  86275_00060_00003  \\\n",
      "0               0.65                    A               0.78   \n",
      "1               0.87                    A               1.40   \n",
      "2               1.68                    A               3.02   \n",
      "3               2.27                    A               2.61   \n",
      "4               1.68                    A               2.05   \n",
      "\n",
      "  86275_00060_00003_cd  \n",
      "0                    A  \n",
      "1                    A  \n",
      "2                    A  \n",
      "3                    A  \n",
      "4                    A  \n",
      "  agency_cd   site_no    datetime  flow mode\n",
      "0      USGS  02096846  2011-01-01  0.78    A\n",
      "1      USGS  02096846  2011-01-02  1.40    A\n",
      "2      USGS  02096846  2011-01-03  3.02    A\n",
      "3      USGS  02096846  2011-01-04  2.61    A\n",
      "4      USGS  02096846  2011-01-05  2.05    A\n",
      "Good! No missing flow data!\n",
      "写入成功！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "site_id = '02096846'\n",
    "year1 = 2011\n",
    "year2 = 2012\n",
    "# url中除了site_id外，还有两个参数设置需要注意，一个是parameter，也就是数据类型，这里00060表示径流的编号；另一个就是statistics，即数据的值类型，这里00003表示均值\n",
    "# 根据官方的Q&A：How do I get help refining my URL query? Please tell us what you want to do by sending an email to gs-w_support_nwisweb@usgs.gov.\n",
    "# 这里url只给出了径流的编号，统计值的编号暂时不知道如何给出\n",
    "url = 'https://waterdata.usgs.gov/nwis/dv?cb_00060=on&format=rdb&site_no={}&\\\n",
    "referred_module=sw&period=&begin_date={}-01-01&end_date={}-12-31'.format(site_id,year1,year2)\n",
    "print(url)\n",
    "# pandas从0.19.2及之后的版本都可以直接从url中读取数据，skiprows需要读文件的时候判断\n",
    "# 下载的数据文件，数字的起始行数不同，不过都是最后一行注释“#”之后第三行\n",
    "skip_rows_index=list(range(0,28))\n",
    "print(type(skip_rows_index))\n",
    "print(skip_rows_index)\n",
    "skip_rows_index.append(29)\n",
    "print(skip_rows_index)\n",
    "df_flow = pd.read_csv(url, skiprows=skip_rows_index, sep='\\t', dtype={'site_no': str})\n",
    "print(df_flow[0:5])\n",
    "\n",
    "# 原数据的列名并不好用，这里修改\n",
    "columns_names=df_flow.columns.tolist()\n",
    "for column_name in columns_names:\n",
    "    if '_00060_00003' in column_name and '_00060_00003_cd' not in column_name:\n",
    "        df_flow.rename(columns={column_name:'flow'},inplace=True)\n",
    "    elif '_00060_00003_cd' in column_name:\n",
    "        df_flow.rename(columns={column_name:'mode'},inplace=True)\n",
    "\n",
    "columns=['agency_cd','site_no','datetime','flow','mode']\n",
    "df_flow=df_flow.loc[:,columns]\n",
    "print(df_flow[0:5])\n",
    "\n",
    "df_flow.index = pd.DatetimeIndex(df_flow.datetime)\n",
    "# 如果需要转换单位：convert unit: f3/s --> m3/s\n",
    "df_flow.flow *= 0.0283168\n",
    "if len(df_flow.index) == len(pd.date_range('{}0101'.format(year1), '{}1231'.format(year2),freq='D')):\n",
    "    print('Good! No missing flow data!')\n",
    "else:\n",
    "    print('Opoo! Please check missing data!')\n",
    "    \n",
    "\n",
    "# 通过直接读取网页的方式批量获取数据，然后存入txt文件\n",
    "site_id = '05594100,01013500'\n",
    "url = 'https://waterdata.usgs.gov/nwis/dv?cb_00060=on&format=rdb&site_no={}&\\\n",
    "referred_module=sw&period=&begin_date={}-01-01&end_date={}-12-31'.format(site_id,year1,year2)\n",
    "r = requests.get(url)\n",
    "with open('usgs-test.txt','w') as f:\n",
    "    f.write(r.text)\n",
    "print(\"写入成功！\")\n",
    "\n",
    "# 批量读取数据的方式更快，不过要把数据组织为每个站点的单独页面，需要进行额外处理：用url读取/写入文件后即刻处理。\n",
    "# 这种在数据量较大时有可能过于耗内存，因此最好是利用爬虫相关机制进行处理，这里暂时这样处理。\n",
    "# 首先读取第16行，判断总共有多少个sites的数据被写入\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
